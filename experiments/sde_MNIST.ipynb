{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZQtKphLIfQf",
        "outputId": "b0874598-8360-4589-ad39-7c7120ff35d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchsde'...\n",
            "remote: Enumerating objects: 1620, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 1620 (delta 103), reused 115 (delta 56), pack-reused 1430 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1620/1620), 4.31 MiB | 24.54 MiB/s, done.\n",
            "Resolving deltas: 100% (1107/1107), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/google-research/torchsde.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('./torchsde')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyMAU64DJC7h",
        "outputId": "11e651d7-0a6d-4271-c14e-39626b1178ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/torchsde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDlKH74sI6Qz",
        "outputId": "2b068f96-ff34-469d-887e-5b82f6f7d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t    CONTRIBUTING.md  DOCUMENTATION.md  LICENSE\t       README.md  tests\n",
            "benchmarks  diagnostics      examples\t       pyproject.toml  setup.py   torchsde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsde"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRH7RUCWJM9r",
        "outputId": "7172b6a9-475a-4592-a8c8-560374952e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsde\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from torchsde) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from torchsde) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from torchsde) (2.5.1+cu121)\n",
            "Collecting trampoline>=0.1.2 (from torchsde)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->torchsde) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->torchsde) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->torchsde) (3.0.2)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, torchsde\n",
            "Successfully installed torchsde-0.2.6 trampoline-0.1.2\n",
            "Collecting fire\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=cbf32ca353e81f946a3140271fe4a1dc4c332b0321cabee4613ade712afb25d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### MNIST Dataset Traning Experiment ##############\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets, transforms\n",
        "import torchsde\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "class MNISTSDEModel(torchsde.SDEIto):\n",
        "    def __init__(self, data_dim, hidden_dim=64, noise_type='diagonal'):\n",
        "        super().__init__(noise_type=noise_type)\n",
        "\n",
        "        self.fc1 = nn.Linear(data_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, data_dim)\n",
        "        self.sigma = nn.Parameter(torch.ones(data_dim))\n",
        "\n",
        "    def f(self, t, x):\n",
        "        # Drift function\n",
        "        h = torch.relu(self.fc1(x))\n",
        "        h = torch.relu(self.fc2(h))\n",
        "        return self.fc3(h)\n",
        "\n",
        "    def g(self, t, x):\n",
        "        # Diffusion function\n",
        "        return self.sigma * torch.ones_like(x)\n",
        "\n",
        "    def h(self, t, x):\n",
        "        # Aux function for SDE\n",
        "        return torch.zeros_like(x)\n",
        "\n",
        "    def sample(self, batch_size, x0, t, dt):\n",
        "\n",
        "        num_steps = int(t / dt)\n",
        "        xs = [x0]\n",
        "        for _ in range(num_steps):\n",
        "            t = torch.tensor([0.0, dt])\n",
        "            x = torchsde.sdeint(self, xs[-1], t, dt=dt)[-1]\n",
        "            xs.append(x)\n",
        "        return torch.stack(xs)\n",
        "\n",
        "def train_mnist_sde(epochs=10, batch_size=128, learning_rate=0.001, validation_split=0.5):\n",
        "    # Normalizing data for our model\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Load MNIST Dataset\n",
        "    full_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    # Split the training and test dataset equally\n",
        "    train_size = int(len(full_dataset) * (1 - validation_split))\n",
        "    test_size = len(full_dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    input_dim = 28 * 28\n",
        "    model = MNISTSDEModel(data_dim=input_dim)\n",
        "\n",
        "    classifier = nn.Sequential(\n",
        "        nn.Linear(input_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 10)\n",
        "    )\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=learning_rate)\n",
        "\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}',\n",
        "                          postfix={'train_loss': 0.0, 'test_accuracy': 0.0})\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_pbar):\n",
        "\n",
        "            data = data.view(data.size(0), -1)\n",
        "\n",
        "            batch_size = data.size(0)\n",
        "            t0, t1 = 0.0, 1.0\n",
        "            ts = torch.tensor([t0, t1])\n",
        "            xs = torchsde.sdeint(model, data, ts, dt=0.1)\n",
        "\n",
        "            outputs = classifier(xs[-1])\n",
        "            loss = criterion(outputs, target)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            train_pbar.set_postfix({\n",
        "                'train_loss': f'{loss.item():.4f}'\n",
        "            })\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            test_pbar = tqdm(test_loader, desc='Testing', leave=False)\n",
        "            for data, target in test_pbar:\n",
        "                data = data.view(data.size(0), -1)\n",
        "                xs = model.sample(data.size(0), x0=data, t=t0, dt=0.1)\n",
        "                outputs = classifier(xs[-1])\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "                test_pbar.set_postfix({'accuracy': f'{100 * correct / total:.2f}%'})\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        train_pbar.close()\n",
        "\n",
        "        print(f'Epoch {epoch+1}:')\n",
        "        print(f'  Train Loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    print(f\"Best Test Accuracy: {max(test_accuracies):.2f}%\")\n",
        "\n",
        "    return model, classifier, train_losses, test_accuracies\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    model, classifier, train_losses, test_accuracies = train_mnist_sde(epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O8P3YtF-BiR",
        "outputId": "16d23775-0377-48a6-a1cb-911c0ef38395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 235/235 [01:40<00:00,  2.33it/s, train_loss=0.3029]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "  Train Loss: 0.4158\n",
            "  Test Accuracy: 79.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 235/235 [01:41<00:00,  2.32it/s, train_loss=0.1341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "  Train Loss: 0.1839\n",
            "  Test Accuracy: 73.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 235/235 [01:42<00:00,  2.29it/s, train_loss=0.1850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3:\n",
            "  Train Loss: 0.1302\n",
            "  Test Accuracy: 69.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 235/235 [01:41<00:00,  2.32it/s, train_loss=0.0815]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4:\n",
            "  Train Loss: 0.1089\n",
            "  Test Accuracy: 69.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 235/235 [01:44<00:00,  2.26it/s, train_loss=0.0733]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5:\n",
            "  Train Loss: 0.0896\n",
            "  Test Accuracy: 65.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 235/235 [01:38<00:00,  2.40it/s, train_loss=0.0703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6:\n",
            "  Train Loss: 0.0719\n",
            "  Test Accuracy: 61.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 235/235 [01:41<00:00,  2.32it/s, train_loss=0.0497]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7:\n",
            "  Train Loss: 0.0617\n",
            "  Test Accuracy: 63.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 235/235 [01:42<00:00,  2.29it/s, train_loss=0.0123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8:\n",
            "  Train Loss: 0.0537\n",
            "  Test Accuracy: 69.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 235/235 [01:43<00:00,  2.28it/s, train_loss=0.0542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9:\n",
            "  Train Loss: 0.0498\n",
            "  Test Accuracy: 64.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 235/235 [01:41<00:00,  2.31it/s, train_loss=0.0847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10:\n",
            "  Train Loss: 0.0433\n",
            "  Test Accuracy: 63.69%\n",
            "\n",
            "Training Complete!\n",
            "Best Test Accuracy: 79.71%\n"
          ]
        }
      ]
    }
  ]
}